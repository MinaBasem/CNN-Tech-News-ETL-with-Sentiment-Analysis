{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n"
     ]
    }
   ],
   "source": [
    "companies_from_csv = pd.read_csv('companies.csv')\n",
    "companies_list = companies_from_csv['company'].tolist()\n",
    "print(len(companies_list))\n",
    "#print(companies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>505 OpenAI employees threaten to quit and call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Sam Altman is back at OpenAI … with a guest badge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>OpenAI unveils latest AI model, customizable G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>500+ OpenAI employees threaten to quit over CE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook, Instagram</td>\n",
       "      <td>Facebook and Instagram users in Europe can now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Microsoft, OpenAI</td>\n",
       "      <td>Microsoft CEO doesn’t dismiss possibility of S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apple, X</td>\n",
       "      <td>Pro-Nazi posts next to Apple ads: Elon Musk’s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>OpenAI drama continues: Sam Altman may be mull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X</td>\n",
       "      <td>Ad execs encourage X CEO Linda Yaccarino to qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple will make a big change to iPhone message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>OpenAI’s turmoil is about more than Sam Altman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CNN</td>\n",
       "      <td>See CNN co-anchors absolutely lose it over Joh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company                                           Headline\n",
       "0                OpenAI  505 OpenAI employees threaten to quit and call...\n",
       "1                OpenAI  Sam Altman is back at OpenAI … with a guest badge\n",
       "2                OpenAI  OpenAI unveils latest AI model, customizable G...\n",
       "3                OpenAI  500+ OpenAI employees threaten to quit over CE...\n",
       "4   Facebook, Instagram  Facebook and Instagram users in Europe can now...\n",
       "5     Microsoft, OpenAI  Microsoft CEO doesn’t dismiss possibility of S...\n",
       "6              Apple, X  Pro-Nazi posts next to Apple ads: Elon Musk’s ...\n",
       "7                OpenAI  OpenAI drama continues: Sam Altman may be mull...\n",
       "8                     X  Ad execs encourage X CEO Linda Yaccarino to qu...\n",
       "9                 Apple  Apple will make a big change to iPhone message...\n",
       "10               OpenAI     OpenAI’s turmoil is about more than Sam Altman\n",
       "11                  CNN  See CNN co-anchors absolutely lose it over Joh..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract\n",
    "\n",
    "page = requests.get('https://edition.cnn.com/business/tech').text\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "section_element = soup.find('section', class_='layout__wrapper layout-no-rail__wrapper')\n",
    "span_elements = section_element.find_all('span', class_='container__headline-text')\n",
    "links = soup.find_all('a', class_='container__link container__link--type-article container_lead-plus-headlines-with-images__link')\n",
    "more_links = soup.find_all('a', class_='container__link container__link--type-video container_lead-plus-headlines__link')\n",
    "even_more_links = soup.find_all('a', class_='container__link container__link--type-article container_lead-plus-headlines__link')\n",
    "\n",
    "links_list = []\n",
    "for link in links:\n",
    "    links_list.append(str(link['href']))\n",
    "\n",
    "for link in more_links:\n",
    "    links_list.append(str(link['href']))\n",
    "\n",
    "for link in even_more_links:\n",
    "    links_list.append(str(link['href']))\n",
    "\n",
    "headlines = []\n",
    "for headline in span_elements:\n",
    "    headline = str(headline.contents)\n",
    "    headline = headline[2:]\n",
    "    headline = headline[:-2]\n",
    "    headlines.append(headline)\n",
    "\n",
    "headlines = set(headlines)              # To remove duplicates (may occur)\n",
    "\n",
    "companies_pattern = re.compile(r'\\b(?:' + '|'.join(map(re.escape, companies_list)) + r')\\b', flags=re.IGNORECASE)\n",
    "\n",
    "matching_company_words = [              # Extract words from headlines that match entire company names\n",
    "    [\n",
    "        word for word in re.findall(r'\\b\\w+\\b', headline)\n",
    "        if companies_pattern.fullmatch(word) and word.lower() not in {'', ''}  # Exclude certain words\n",
    "    ]\n",
    "    for headline in headlines\n",
    "]\n",
    "\n",
    "filtered_headlines = [                  # Filter headlines that include matching_company_words\n",
    "    headline for headline, company_words in zip(headlines, matching_company_words) if any(company_words)\n",
    "]\n",
    "\n",
    "matching_company_words = [item for item in matching_company_words if item]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Company\", \"Headline\"])      # Creation of dataframe using the  matching_company_words and filtered_headlines lists\n",
    "df[\"Company\"] = matching_company_words\n",
    "df[\"Company\"] = df[\"Company\"].astype(str).str[1:-1]\n",
    "df[\"Company\"] = df[\"Company\"].str.replace(\"'\", '')\n",
    "df[\"Headline\"] = filtered_headlines\n",
    "\n",
    "df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links extraction complete\n"
     ]
    }
   ],
   "source": [
    "## OBTAIN EACH HEADLINE'S ARTICLE LINK\n",
    "\n",
    "search_links = []\n",
    "\n",
    "service = Service(executable_path='/usr/local/bin/chromedriver')\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "for headline in filtered_headlines:         # Queries CNN page for news that match the headline\n",
    "    headline = headline.replace(' ', '+')\n",
    "    search_url = 'https://edition.cnn.com/search?q=' + headline + '&sort=relevance&from=0&size=10&page=1&types=all&section='\n",
    "    #print(search_url)\n",
    "\n",
    "    driver.get(search_url)\n",
    "    time.sleep(10)\n",
    "    updated_page_content = driver.page_source\n",
    "    cnn_search_soup = BeautifulSoup(updated_page_content,'html.parser')\n",
    "    links_element = cnn_search_soup.find('a', class_='container__link container__link--type-NewsArticle container_list-images-with-description__link')\n",
    "    search_links.append(links_element['href'])\n",
    "\n",
    "driver.quit()\n",
    "print(\"Links extraction complete\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles extraction complete\n"
     ]
    }
   ],
   "source": [
    "## EXTRACT THE ARTICLES FROM THE LINKS OBTAINED EARLIER\n",
    "\n",
    "articles_list = []\n",
    "\n",
    "for link in search_links:       # for each page\n",
    "    page = requests.get(link).text\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    paragraph_elements = soup.find_all('p', class_='paragraph inline-placeholder')\n",
    "    full_article_string = ''\n",
    "    for article in paragraph_elements:\n",
    "        content = str(article.contents)\n",
    "        content = clean_text = re.sub(r'<.*?>', '', content)\n",
    "        replacements = [(\"n     \", ''), (\"['\\ \", ''), (\"n  ']\", '')]\n",
    "        for char, replacement in replacements:\n",
    "            if char in content:\n",
    "                content = content.replace(char, replacement)\n",
    "        content = str(content)\n",
    "        #print(content)\n",
    "        full_article_string = full_article_string + str(content)\n",
    "    articles_list.append(full_article_string)\n",
    "    #print(\"--------------------XXXXXXXX----------XXXXXXXX--------------------\")\n",
    "\n",
    "#print(articles_list)\n",
    "print('Articles extraction complete')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTION TO SUMMARIZE ARTICLES\n",
    "\n",
    "import openai\n",
    "from openai._client import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key = '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',\n",
    ")\n",
    "\n",
    "def get_response(prompt): \n",
    "    completions = client.completions.create(\n",
    "        model = \"text-davinci-003\",\n",
    "        prompt = prompt,\n",
    "        stream = False,\n",
    "        max_tokens = 1024,\n",
    "        n = 1,\n",
    "        stop = None,\n",
    "        temperature = 0.5,\n",
    "    )\n",
    "    message = completions.choices[0].text\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization complete\n"
     ]
    }
   ],
   "source": [
    "## SUMMARIZE ARTICLES TO 40 WORDS\n",
    "\n",
    "articles_summary_list = []\n",
    "for article in articles_list:\n",
    "    summary = get_response(\"Please summarize the following text to 40 words, and determine whether this is positive or negative news: \" + article)\n",
    "    summary = summary.replace(\"\\n\", \"\")\n",
    "    articles_summary_list.append(summary)\n",
    "    #print(summary)\n",
    "    time.sleep(21)\n",
    "\n",
    "df[\"Summary\"] = articles_summary_list\n",
    "print(\"Summarization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/Mina/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Article Sentiment</th>\n",
       "      <th>Article Sentiment Description</th>\n",
       "      <th>Summary Sentiment</th>\n",
       "      <th>Summary Sentiment Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>505 OpenAI employees threaten to quit and call...</td>\n",
       "      <td>Hundreds of OpenAI staffers are calling for th...</td>\n",
       "      <td>-0.7044</td>\n",
       "      <td>Bad News</td>\n",
       "      <td>-0.9183</td>\n",
       "      <td>Bad News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Sam Altman is back at OpenAI … with a guest badge</td>\n",
       "      <td>Positive: Sam Altman's return to OpenAI is bei...</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>Good News</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>Good News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>OpenAI unveils latest AI model, customizable G...</td>\n",
       "      <td>OpenAI unveiled a series of AI tool updates, i...</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>Good News</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>Good News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>500+ OpenAI employees threaten to quit over CE...</td>\n",
       "      <td>Hundreds of OpenAI staffers have called for th...</td>\n",
       "      <td>-0.7044</td>\n",
       "      <td>Bad News</td>\n",
       "      <td>-0.8860</td>\n",
       "      <td>Bad News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook, Instagram</td>\n",
       "      <td>Facebook and Instagram users in Europe can now...</td>\n",
       "      <td>Positive news: Meta announced that users in Eu...</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>Good News</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>Good News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Microsoft, OpenAI</td>\n",
       "      <td>Microsoft CEO doesn’t dismiss possibility of S...</td>\n",
       "      <td>Sam Altman may return as CEO of OpenAI, but ne...</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>Good News</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>Good News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apple, X</td>\n",
       "      <td>Pro-Nazi posts next to Apple ads: Elon Musk’s ...</td>\n",
       "      <td>Negative: Elon Musk is threatening to sue the ...</td>\n",
       "      <td>-0.9922</td>\n",
       "      <td>Bad News</td>\n",
       "      <td>-0.9648</td>\n",
       "      <td>Bad News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>OpenAI drama continues: Sam Altman may be mull...</td>\n",
       "      <td>Positive news: Sam Altman is back at OpenAI, a...</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>Good News</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>Bad News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X</td>\n",
       "      <td>Ad execs encourage X CEO Linda Yaccarino to qu...</td>\n",
       "      <td>A \"groundswell\" of advertising executives have...</td>\n",
       "      <td>-0.4755</td>\n",
       "      <td>Bad News</td>\n",
       "      <td>-0.8176</td>\n",
       "      <td>Bad News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple will make a big change to iPhone message...</td>\n",
       "      <td>Apple announced plans to adopt a messaging sta...</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>Good News</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>Good News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>OpenAI’s turmoil is about more than Sam Altman</td>\n",
       "      <td>OpenAI may be considering the return of recent...</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>Good News</td>\n",
       "      <td>-0.7717</td>\n",
       "      <td>Bad News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CNN</td>\n",
       "      <td>See CNN co-anchors absolutely lose it over Joh...</td>\n",
       "      <td>After enduring a tumultuous year of internal s...</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>Good News</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>Good News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company                                           Headline  \\\n",
       "0                OpenAI  505 OpenAI employees threaten to quit and call...   \n",
       "1                OpenAI  Sam Altman is back at OpenAI … with a guest badge   \n",
       "2                OpenAI  OpenAI unveils latest AI model, customizable G...   \n",
       "3                OpenAI  500+ OpenAI employees threaten to quit over CE...   \n",
       "4   Facebook, Instagram  Facebook and Instagram users in Europe can now...   \n",
       "5     Microsoft, OpenAI  Microsoft CEO doesn’t dismiss possibility of S...   \n",
       "6              Apple, X  Pro-Nazi posts next to Apple ads: Elon Musk’s ...   \n",
       "7                OpenAI  OpenAI drama continues: Sam Altman may be mull...   \n",
       "8                     X  Ad execs encourage X CEO Linda Yaccarino to qu...   \n",
       "9                 Apple  Apple will make a big change to iPhone message...   \n",
       "10               OpenAI     OpenAI’s turmoil is about more than Sam Altman   \n",
       "11                  CNN  See CNN co-anchors absolutely lose it over Joh...   \n",
       "\n",
       "                                              Summary  Article Sentiment  \\\n",
       "0   Hundreds of OpenAI staffers are calling for th...            -0.7044   \n",
       "1   Positive: Sam Altman's return to OpenAI is bei...             0.9497   \n",
       "2   OpenAI unveiled a series of AI tool updates, i...             0.9888   \n",
       "3   Hundreds of OpenAI staffers have called for th...            -0.7044   \n",
       "4   Positive news: Meta announced that users in Eu...             0.9753   \n",
       "5   Sam Altman may return as CEO of OpenAI, but ne...             0.9497   \n",
       "6   Negative: Elon Musk is threatening to sue the ...            -0.9922   \n",
       "7   Positive news: Sam Altman is back at OpenAI, a...             0.9497   \n",
       "8   A \"groundswell\" of advertising executives have...            -0.4755   \n",
       "9   Apple announced plans to adopt a messaging sta...             0.9907   \n",
       "10  OpenAI may be considering the return of recent...             0.9888   \n",
       "11  After enduring a tumultuous year of internal s...             0.5445   \n",
       "\n",
       "   Article Sentiment Description  Summary Sentiment  \\\n",
       "0                       Bad News            -0.9183   \n",
       "1                      Good News             0.4939   \n",
       "2                      Good News             0.9062   \n",
       "3                       Bad News            -0.8860   \n",
       "4                      Good News             0.7096   \n",
       "5                      Good News             0.7096   \n",
       "6                       Bad News            -0.9648   \n",
       "7                      Good News            -0.2732   \n",
       "8                       Bad News            -0.8176   \n",
       "9                      Good News             0.4767   \n",
       "10                     Good News            -0.7717   \n",
       "11                     Good News             0.7184   \n",
       "\n",
       "   Summary Sentiment Description  \n",
       "0                       Bad News  \n",
       "1                      Good News  \n",
       "2                      Good News  \n",
       "3                       Bad News  \n",
       "4                      Good News  \n",
       "5                      Good News  \n",
       "6                       Bad News  \n",
       "7                       Bad News  \n",
       "8                       Bad News  \n",
       "9                      Good News  \n",
       "10                      Bad News  \n",
       "11                     Good News  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ARTICLE AND SUMMARY SENTIMENT SCORE AND CLASSIFICATION\n",
    "\n",
    "nltk.download('vader_lexicon')  # Download the VADER lexicon\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "article_sentiment_list = []\n",
    "for article in articles_list:\n",
    "    sentiment = sid.polarity_scores(article)\n",
    "    article_sentiment_list.append(sentiment['compound'])\n",
    "\n",
    "article_sentiment_description = []\n",
    "for sentiment in article_sentiment_list:\n",
    "    if sentiment >= 0.05:\n",
    "        article_sentiment_description.append('Good News')\n",
    "        sentiment = 'Positive'\n",
    "    elif sentiment <= -0.05:\n",
    "        article_sentiment_description.append('Bad News')\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        article_sentiment_description.append('Neutral')\n",
    "        sentiment = 'Neutral'\n",
    "\n",
    "df['Article Sentiment'] = article_sentiment_list\n",
    "df['Article Sentiment Description'] = article_sentiment_description\n",
    "\n",
    "summary_sentiment_list = []\n",
    "for summary in articles_summary_list:\n",
    "    sentiment = sid.polarity_scores(summary)\n",
    "    summary_sentiment_list.append(sentiment['compound'])\n",
    "\n",
    "summary_sentiment_description = []\n",
    "for sentiment in summary_sentiment_list:\n",
    "    if sentiment >= 0.05:\n",
    "        summary_sentiment_description.append('Good News')\n",
    "        sentiment = 'Positive'\n",
    "    elif sentiment <= -0.05:\n",
    "        summary_sentiment_description.append('Bad News')\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        summary_sentiment_description.append('Neutral')\n",
    "        sentiment = 'Neutral'\n",
    "\n",
    "df['Summary Sentiment'] = summary_sentiment_list\n",
    "df['Summary Sentiment Description'] = summary_sentiment_description\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "df.to_csv('loaded_data.csv', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_format = '%Y-%h-%d-%H:%M:%S'          # Year-Monthname-Day-Hour-Minute-Second \n",
    "now = datetime.now()                            # get current timestamp \n",
    "timestamp = now.strftime(timestamp_format) \n",
    "with open(\"project_log.txt\", \"a\") as f: \n",
    "    f.write(timestamp + ': ' + \"Data appended \" + '\\n') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
